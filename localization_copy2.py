# -*- coding: utf-8 -*-
"""localization-Copy2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EvZhgB5s5YMBx_3tpnpj-KNr2EfSvXan

# SDP
"""

!pip install -f https://download.mosek.com/stable/wheel/index.html Mosek

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

import math
import random
import numpy as np
import pickle
import mosek
from numpy import linalg as LA
from numpy import array
from mosek.fusion import *
import glob

PT= -30
eta= 2

def rss2dis(r):  # convert RSSI to distance
    if r== 0:
        return 0
    d= 10.0**((PT-r)/(10.0*eta))
    return d

def distance(node1, node2):
    return math.sqrt((node1[0]-node2[0])**2+(node1[1]-node2[1])**2)

def error_cal(pX, pXpredict):  # calculate average location estimation error, pX= true positions, pXpredict= estimated positions 
    err= np.mean([distance(pX[i],pXpredict[i]) for i in range(len(pX))])    
    return err

def SDP(pA, dAX, dXX, sigma2_AX, sigma2_XX):
    nX = len(dXX)
    nA = len(pA)
    
    M = Model('Localization Problem')
    Y = M.variable("Y", Domain.inPSDCone(nX))
    Z = M.variable("Z", Domain.inPSDCone(nX+2))

    M.constraint(Z.index(0,0), Domain.equalsTo(1.0))
    M.constraint(Z.index(1,1), Domain.equalsTo(1.0))
    M.constraint(Z.index(0,1), Domain.equalsTo(0.0))
    M.constraint(Z.index(1,0), Domain.equalsTo(0.0))
    
    #for i in range(nX):
    #    M.constraint(Z.index(0, i+2), Domain.greaterThan(0.0))
    #    M.constraint(Z.index(1, i+2), Domain.greaterThan(0.0))
    #    M.constraint(Z.index(0, i+2), Domain.lessThan(4.0))
    #    M.constraint(Z.index(1, i+2), Domain.lessThan(4.0))
        
    expr = Expr.sub(Z.slice([2,2],[nX+2,nX+2]), Y)

    M.constraint(expr, Domain.equalsTo(0.0))
    
    D = []

    for i in range(nA):
        D.append([])
        for j in range(nX):
            vect = [0] * (nX + 2)
            vect[0] = pA[i][0]
            vect[1] = pA[i][1]
            vect[j + 2] = -1

            expr = Expr.mul(vect, Z)
            expr = Expr.mul(expr, vect)


            D[i].append(M.variable("D" + str(i) + "_" + str(j), Domain.inPSDCone(2)))
            expr = Expr.sub(expr, D[i][j].index(1,1))

            M.constraint(expr, Domain.equalsTo(0.0))
            M.constraint(D[i][j].index(0,0), Domain.equalsTo(1.0))
 
    Alpha = []

    for i in range(nA):
        Alpha.append([])
        for j in range(nX):
            Alpha[i].append(M.variable("Alpha" + str(i) + "_" + str(j), Domain.unbounded()))

            expr = Expr.mul([dAX[i][j], -1], D[i][j])
            expr = Expr.mul(expr, [dAX[i][j], -1])
            expr = Expr.sub(expr, Alpha[i][j])

            M.constraint(expr, Domain.equalsTo(0.0))
            
    V = []

    for i in range(nX):
        V.append([])
        for j in range(nX):
            if i == j:
                V[i].append(0)
                continue

            vect = [0] * nX
            vect[i] = 1
            vect[j] = -1

            expr = Expr.mul(vect, Y)
            expr = Expr.mul(expr, vect)


            V[i].append(M.variable("V" + str(i) + "_" + str(j), Domain.inPSDCone(2)))
            expr = Expr.sub(expr, V[i][j].index(1,1))

            M.constraint(expr, Domain.equalsTo(0.0))
            M.constraint(V[i][j].index(0,0), Domain.equalsTo(1.0))           
            
    Gamma = []

    for i in range(nX):
        Gamma.append([])
        for j in range(nX):
            if i == j:
                Gamma[i].append(0)
                continue

            Gamma[i].append(M.variable("Gamma" + str(i) + "_" + str(j), Domain.unbounded()))
            expr = Expr.mul([dXX[i][j], -1], V[i][j])
            
            expr = Expr.mul(expr, [dXX[i][j], -1])
            expr = Expr.sub(expr, Gamma[i][j])

            M.constraint(expr, Domain.equalsTo(0.0))

    expr = Expr.zeros(1)

    for i in range(nA):
        for j in range(nX):
            
            expr2 = Expr.mul(1.0/sigma2_AX[i][j]**2.0, Alpha[i][j])
            
            expr = Expr.add(expr, expr2)

    for i in range(nX):
        for j in range(nX):
            if i == j:
                continue    
            expr2 = Expr.mul(1.0/sigma2_XX[i][j]**2.0, Gamma[i][j])
            
            expr = Expr.add(expr, expr2)        

    M.objective(ObjectiveSense.Minimize, expr) 
    
    M.acceptedSolutionStatus(AccSolutionStatus.Anything)
    
    M.solve()
    
     
    ZSolution = Z.level()
    solution = []
    for i in range(nX):
        newSol = (ZSolution[i + 2], ZSolution[nX + 2 + i + 2])
        solution.append(newSol)

    return solution

"""## Localization"""

def draw(pA, pX, pXraw, pXrefine):

    A= np.array(pA)
    X= np.array(pX)
    Xraw= np.array(pXraw)
    Xrefine= np.array(pXrefine)
    
    plt.scatter(A[:,0], A[:,1], color='red', marker='o',
            label='Anchors')
   
    plt.scatter(X[:,0], X[:,1], color='blue', marker='x',
            label='True positions')
    
    plt.scatter(Xraw[:,0], Xraw[:,1], color='yellowgreen', marker='.',
            label='Raw estimated positions')
    
    plt.scatter(Xrefine[:,0], Xrefine[:,1], color='navy', marker='.',
            label='Refined estimated positions')
    
    for i in range(len(X)):
        plt.plot([ X[i,0],  Xraw[i,0]], [ X[i,1], Xraw[i,1]], 'yellowgreen')
        plt.plot([ X[i,0],  Xrefine[i,0]], [ X[i,1], Xrefine[i,1]], 'navy')
    
        
    plt.axis('equal')
    plt.legend(loc='lower center', bbox_to_anchor=(.5, -.3),
          ncol=2, fancybox=True)
    plt.show()

    return 0

f = open("c://Users//Vorapong//Documents//topology.txt", "rb")
n = 9
bigNumber = n*n
adjacencyMatrix = []
count = 0
R = [0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]

for line in f:
    incident = line.split()
    print(incident)
    toAdd = [bigNumber] * n
    for element in incident:
        toAdd[int(element) - 1] = (R[count] + R[int(element)-1]) * 1.0
    toAdd[count] = 0
    count = count + 1
    adjacencyMatrix.append(toAdd)

    
for k in range(n):
    for i in range(n):
        for j in range(n):
            if adjacencyMatrix[i][j] > adjacencyMatrix[i][k] + adjacencyMatrix[k][j]:
                adjacencyMatrix[i][j] = adjacencyMatrix[i][k] + adjacencyMatrix[k][j]


print(adjacencyMatrix) 
                
A = [0,1,2]
X = [3,4,5,6,7,8]
pA = [[0.5,0.5],[1.52,0.51],[2.52,0.51]]

dAX= [[adjacencyMatrix[i][j] for j in X] for i in A]      
dXX= [[adjacencyMatrix[i][j] for j in X] for i in X] 

sigma2_AX = np.array(dAX)
sigma2_XX = np.array(dXX)

pX = SDP(pA, dAX, dXX, sigma2_AX, sigma2_XX)

for point in pX:
    print(str(point[0]) + "\t" + str(point[1]))


draw(pA, pX, pX, pX)

def localization(anchor_ratio, filename):
    # anchor_ratio= #anchor nodes / #all nodes: anchors are chosen randomly V: What are anchors and the anchor_ratio?
    # if anchor_ratio == 0: Automatically choose 4 anchor nodes at the conners
    
    
    f= open(filename, 'rb')
    #data= pickle.load(f)  #load data
    data =  pickle.load(f) 
    #print(data)
    f.close()
    
    
    d_out={}  # is to save results
    
    #for d in data:  # using full data set
    for d in range(1):  #just for testing: use only 1 data set, please remove this line and use the upper line after editing SDP   
        #print(i)
        P= np.array(data[d]['P'])   # node positions        
        Rraw= np.array(data[d]['R'])  # raw rssi
        Rrefine= np.array(data[d]['Rrefine'])  # refined rssi
        d_out[d]={} #output
        
        N= len(P)  # number of all nodes
        
        if anchor_ratio > 0.001:  #choose anchor nodes randomly
            nA= int( N* anchor_ratio) # number of anchors
            nX= N- nA
            random_list= list(range(N))
            random.shuffle(random_list)
            indexA= random_list[:nA]  # randomly choose nA nodes used as anchors
            indexX= random_list[nA:]
        
        else: # choose 4 anchor nodes near the coners
            indexA = [np.argmin(P[:,0]+ P[:,1]), np.argmin(max(P[:,0])- P[:,0]+ P[:,1]), np.argmin(max(P[:,1])+ P[:,0]- P[:,1]),np.argmin(max(P[:,0])+max(P[:,1])- P[:,0]- P[:,1])]  
            indexX= [i for i in list(range(N)) if i not in indexA]
            nA= len(indexA) # number of anchors = 4
            nX= N- nA
                  
        
        d_out[d]['pA']= pA= [P[i] for i in indexA] # positions of anchors
        d_out[d]['pX']= pX=  [P[i] for i in indexX]   # target node positions
        
       
        # SDP data prepration
        dAX_raw= [[rss2dis(Rraw[i][j]) for j in indexX] for i in indexA ]   #estimated distance from tagert nodes to anchor nodes through RSSI       
        dXX_raw= [[rss2dis(Rraw[i][j]) for j in indexX] for i in indexX ]

        dAX_refine= [[rss2dis(Rrefine[i][j]) for j in indexX] for i in indexA]      
        dXX_refine= [[rss2dis(Rrefine[i][j]) for j in indexX] for i in indexX]    
        
   
        sigma2_AX_raw= np.array(dAX_raw)
        sigma2_XX_raw= np.array(dXX_raw)
    
        sigma2_AX_refine= np.array(dAX_refine)
        sigma2_XX_refine= np.array(dXX_refine)
        
        #### for testing SDP####
        dAX= [[distance(P[i], P[j]) for j in indexX] for i in indexA]  # Correct distances
        dXX= [[distance(P[i], P[j]) for j in indexX] for i in indexX]
 
        sigma2_AX= np.array(dAX)
        sigma2_XX= np.array(dXX)
        pXpredict= SDP(pA, dAX, dXX, sigma2_AX, sigma2_XX)   # SDP localization estimation using correct data set

        print(LA.norm(np.array(pX)- np.array(pXpredict)))
        
        #print(LA.norm(np.array(pX)- np.array(pXpredict))> 20):  # if the localization error is large, something must be wrong
            #print('error: something wrong')
            #return -1
            
        #### testing SDP end ####

        
        ######## input SDP procedure here ####
        d_out[d]['pXraw']= pXraw= SDP(pA, dAX_raw, dXX_raw, sigma2_AX, sigma2_XX)   # SDP localization estimation
        d_out[d]['pXrefine']= pXrefine= SDP(pA, dAX_refine, dXX_refine, sigma2_AX, sigma2_XX)
        #####  SDP end  #####
        
        
        #####################################################################
        
        draw(pA, pX, pXraw, pXrefine)
        print(error_cal(pX, pXraw))
        print(error_cal(pX, pXrefine))
        
        #test the input data      
        #print(LA.norm(np.array(dAX)- np.array(dAX_raw)))
        #print(LA.norm(np.array(dAX)- np.array(dAX_refine)))
        #print(LA.norm(np.array(dXX)- np.array(dXX_raw)))
        #print(LA.norm(np.array(dXX)- np.array(dXX_refine)))

  
    return d_out

"""## Visualization"""

def draw(pA, pX, pXraw, pXrefine):

    A= np.array(pA)
    X= np.array(pX)
    Xraw= np.array(pXraw)
    Xrefine= np.array(pXrefine)
    
    plt.scatter(A[:,0], A[:,1], color='red', marker='o',
            label='Anchors')
   
    plt.scatter(X[:,0], X[:,1], color='blue', marker='x',
            label='True positions')
    
    plt.scatter(Xraw[:,0], Xraw[:,1], color='yellowgreen', marker='.',
            label='Raw estimated positions')
    
    plt.scatter(Xrefine[:,0], Xrefine[:,1], color='navy', marker='.',
            label='Refined estimated positions')
    
    for i in range(len(X)):
        plt.plot([ X[i,0],  Xraw[i,0]], [ X[i,1], Xraw[i,1]], 'yellowgreen')
        plt.plot([ X[i,0],  Xrefine[i,0]], [ X[i,1], Xrefine[i,1]], 'navy')
    
        
    plt.axis('equal')
    plt.legend(loc='lower center', bbox_to_anchor=(.5, -.3),
          ncol=2, fancybox=True)
    plt.show()

    return 0

# just for testing the draw
pA= [[1,0], [3,4]]
pX=  [[2,3], [4,5]]
pXraw= [[2,3.5], [4,5.5]]
pXrefine= [[2.2,3], [4.2,5]]
draw(pA, pX, pXraw, pXrefine)

"""## main"""

fname= 'refined_raw_gauss_grid'  # grid layout
files = glob.glob('C:/Users/Vorapong/Downloads/SDP_data/data_set/N49/*.csv')

for file in files:
    #anchor_ratio= 0.2  # random anchors: percentage of nodes are anchors
    anchor_ratio= 0.0  # choose 4 anchors at the conners
    d= localization(anchor_ratio, file)

    f= open(file + "result", 'w+b')


    pickle.dump(d, f)
    f.close()

# use each one of the following files for different test beds 
fname= 'refined_raw_gauss_grid'  # grid layout

#anchor_ratio= 0.2  # random anchors: percentage of nodes are anchors
anchor_ratio= 0.0  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()

fname= 'refined_raw_gauss_random'  # random layout

#anchor_ratio= 0.2  # random anchors: percentage of nodes are anchors
anchor_ratio= 0.0  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()

fname= 'refined_raw_rayleigh_random'  # random layout


#anchor_ratio= 0.2  # random anchors: percentage of nodes are anchors
anchor_ratio= 0.0  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()

fname= 'refined_raw_rayleigh_grid'  # random layout

#anchor_ratio= 0.2  # random anchors: percentage of nodes are anchors
anchor_ratio= 0.0  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()
       
# use each one of the following files for different test beds 
fname= 'refined_raw_gauss_grid'  # grid layout

anchor_ratio= 0.2  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()

fname= 'refined_raw_gauss_random'  # random layout

anchor_ratio= 0.2  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()

fname= 'refined_raw_rayleigh_random'  # random layout

anchor_ratio= 0.2  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()

fname= 'refined_raw_rayleigh_grid'  # random layout

anchor_ratio= 0.2  # choose 4 anchors at the conners
d= localization(anchor_ratio,  'data_set/N49/raw/%s.csv' %fname)

f= open('data_set/N49/raw/result_%s.csv' %fname, 'w+b')
   

pickle.dump(d, f)
f.close()



"""## Draw results"""

i= 0  
pA= d[i]['pA']
pX= d[i]['pX']
pXraw=  d[i]['pXraw']
pXrefine=  d[i]['pXrefine']

#pXraw= pX  #just for test
#pXrefine= pX #just for test
draw(pA, pX, pXraw, pXrefine)

#calculate error
err_raw= error_cal(pX, pXraw)
err_refine= error_cal(pX, pXrefine)

print(err_raw, err_refine)

